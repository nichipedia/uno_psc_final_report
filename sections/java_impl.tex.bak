\section{Java Implementation}
We developed a Java implementation of the parallel statistics computation framework. 
Using Java we were able to take advantage of multiple language specific components to aid in development. 
For the parallel portion we leveraged Javaâ€™s executor service. 
The executor service allows us to define individual tasks to be performed on independent threads. 
This maintains our separation of parallel and statistical computation components. 
The parallel portion consists of a single loop that uses Apache Commons CLI interface to read various input and settings used to create the tasks to submit to the executor service.

\par
We used the Java NIO (Non-Blocking Input/Output) package for concurrent reading and writing of gridded data. 
A single shared I/O object was developed and given to each task for concurrent read access to the input grid data. 
To write results back to a gridded structure a writer object was created. 
The writer object, through the use of the NIO FileChannel class, can write data to file in a non-sequential manner. 
This allows the threads to submit computation results to be written in any order without incurring any wait penalties.

\par
For the computational components we developed an interface via the Java Interface language feature. 
Objects called Generators were developed to implement the computation interface. 
The Generators are responsible for reading in the input grid data and performing some type of calculation. 
These are the task objects referenced above that are sent to the executor service. 
Each Generator is given a single shared Collector object. 
The Collector object is responsible for collecting result data and storing it in a queue for the writer object to process.

\par
We created three separate Generator implementations to compute the mean, standard deviation and plane fit for a given input grid. 
We were able to leverage the Apache Commons Math package for the plane fit algorithm. 
The Plane class from this API implements a partial fit algorithm that is accurate enough to fit the scope of this project and is very performant. 
Currently the data produced from these three modules is being used in the initial phases of prediction model training.